{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b0cdf1",
   "metadata": {},
   "source": [
    "# Trabalho 03 – Forecasting com técnica ingênua (Naïve) e rede neural (LSTM)\n",
    "\n",
    "Este notebook é para o **Trabalho 03** da disciplina de Redes Neurais Artificiais (RNA).\n",
    "\n",
    "### Enunciado (resumo)\n",
    "\n",
    "- Usar as **técnicas de forecasting apresentadas em aula** em uma base de dados **diferente** da utilizada em sala.\n",
    "- Usar uma técnica **ingênua (Naïve)** como **baseline**.\n",
    "- Explicar a base usada com **poucas palavras**.\n",
    "- Justificar os **parâmetros** usados para gerar o dataset a partir do array.\n",
    "\n",
    "A ideia aqui é manter o estilo dos trabalhos anteriores: código simples, com alguns comentários\n",
    "sobre as decisões que tomei e pequenos testes que fiz no caminho.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a785b00",
   "metadata": {},
   "source": [
    "## 1. Base de dados usada (explicação rápida)\n",
    "\n",
    "Em vez de usar um dataset pronto da internet, eu gerei uma **série temporal sintética** que imita,\n",
    "de forma bem simples, algo como uma medida de consumo ou demanda ao longo do tempo.\n",
    "\n",
    "A série tem:\n",
    "\n",
    "- uma **tendência leve** (valores vão subindo aos poucos);\n",
    "- uma **sazonalidade** aproximada (um ciclo repetindo mais ou menos a cada 24 pontos);\n",
    "- um pouco de **ruído aleatório**.\n",
    "\n",
    "Essa escolha ajuda a controlar melhor a série (eu sei o que tem dentro dela) e ainda assim é um\n",
    "sinal razoável para testar forecasting com baseline Naïve e com rede neural.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155344e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco de imports principais. Aqui entrou tudo que eu precisei para o trabalho.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Versão do TensorFlow:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc36ac00",
   "metadata": {},
   "source": [
    "## 2. Gerando a série temporal (array base)\n",
    "\n",
    "Aqui eu gero a série `serie`, que será o meu array base para montar o dataset de forecasting.\n",
    "\n",
    "Parâmetros principais escolhidos:\n",
    "\n",
    "- **comprimento da série**: 500 pontos (não é gigante, mas já dá material suficiente para treino/teste);\n",
    "- **tendência**: um termo linear bem pequeno, só para os valores irem subindo devagar;\n",
    "- **sazonalidade**: uma senoide com período por volta de 24 pontos;\n",
    "- **ruído**: um ruído normal com desvio padrão moderado, para não ficar tudo perfeito demais.\n",
    "\n",
    "Depois eu só ploto a série para ver se ela ficou com uma cara “ok”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee4df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comprimento da série\n",
    "n_pontos = 500\n",
    "\n",
    "# eixo de tempo simples\n",
    "t = np.arange(n_pontos)\n",
    "\n",
    "# tendência leve\n",
    "tendencia = 0.03 * t\n",
    "\n",
    "# componente sazonal (período ~24)\n",
    "sazonalidade = 2.0 * np.sin(2 * np.pi * t / 24)\n",
    "\n",
    "# ruído aleatório (não quis exagerar muito aqui)\n",
    "ruido = np.random.normal(loc=0.0, scale=0.5, size=n_pontos)\n",
    "\n",
    "# série final (algo como uma \"demanda\" qualquer)\n",
    "serie = 10 + tendencia + sazonalidade + ruido\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(t, serie, label=\"série sintética\")\n",
    "plt.xlabel(\"tempo (índice)\")\n",
    "plt.ylabel(\"valor\")\n",
    "plt.title(\"Série temporal sintética (tendência + sazonalidade + ruído)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c439ef",
   "metadata": {},
   "source": [
    "## 3. Gerando o dataset a partir do array (janela deslizante)\n",
    "\n",
    "Para usar uma rede neural em forecasting, eu preciso transformar a série 1D em um **dataset supervisonado**.\n",
    "Ou seja, de um array simples como:\n",
    "\n",
    "\\[ x_1, x_2, x_3, \\dots, x_T \\]\n",
    "\n",
    "eu crio pares do tipo:\n",
    "\n",
    "- entrada: \\( [x_t, x_{t+1}, \\dots, x_{t+J-1}] \\)\n",
    "- saída: \\( x_{t+J} \\)\n",
    "\n",
    "onde \\( J \\) é o **tamanho da janela** (quantos pontos passados eu olho para prever o próximo).\n",
    "\n",
    "### Justificativa dos parâmetros\n",
    "\n",
    "- **janela = 24**: escolhi 24 porque na construção da série eu coloquei uma sazonalidade com\n",
    "  período de aproximadamente 24 pontos. Então olhar os últimos 24 valores faz sentido para\n",
    "  capturar pelo menos um “ciclo” completo.\n",
    "- **split treino/teste**: usei os primeiros 80% dos pontos para treino e os últimos 20% para teste.\n",
    "  Como é série temporal, não faz sentido embaralhar; eu mantenho a ordem do tempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11fbb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_dataset(serie, janela):\n",
    "    \"\"\"\n",
    "    Recebe um array 1D (serie) e cria um dataset supervisonado usando janela deslizante.\n",
    "\n",
    "    Para cada posição t, monta:\n",
    "    - X[t] = serie[t : t + janela]\n",
    "    - y[t] = serie[t + janela]\n",
    "\n",
    "    Eu apanhei um pouco na primeira vez que fiz isso porque sempre me confundia\n",
    "    com os índices, então deixei a função separada para não bagunçar o restante\n",
    "    do código.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(serie) - janela):\n",
    "        X.append(serie[i : i + janela])\n",
    "        y.append(serie[i + janela])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "janela = 24  # conforme comentado acima\n",
    "\n",
    "X, y = criar_dataset(serie, janela)\n",
    "print(\"Shape de X:\", X.shape)\n",
    "print(\"Shape de y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando em treino (80%) e teste (20%), respeitando a ordem temporal\n",
    "tamanho_treino = int(len(X) * 0.8)\n",
    "\n",
    "X_treino = X[:tamanho_treino]\n",
    "y_treino = y[:tamanho_treino]\n",
    "\n",
    "X_teste = X[tamanho_treino:]\n",
    "y_teste = y[tamanho_treino:]\n",
    "\n",
    "print(\"Tamanho treino:\", X_treino.shape[0])\n",
    "print(\"Tamanho teste :\", X_teste.shape[0])\n",
    "\n",
    "# reshape para usar na LSTM: (amostras, passos_de_tempo, features)\n",
    "# aqui, \"features\" = 1 porque é uma série univariada\n",
    "X_treino_lstm = X_treino.reshape((X_treino.shape[0], X_treino.shape[1], 1))\n",
    "X_teste_lstm = X_teste.reshape((X_teste.shape[0], X_teste.shape[1], 1))\n",
    "\n",
    "print(\"X_treino_lstm shape:\", X_treino_lstm.shape)\n",
    "print(\"X_teste_lstm shape :\", X_teste_lstm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809ab72d",
   "metadata": {},
   "source": [
    "## 4. Baseline ingênuo (Naïve)\n",
    "\n",
    "Conforme pedido no enunciado, antes de usar rede neural eu preciso ter uma\n",
    "**técnica ingênua (Naïve)** para servir de baseline.\n",
    "\n",
    "Aqui eu usei a versão mais simples possível:\n",
    "\n",
    "> **Previsão = último valor observado** na janela.\n",
    "\n",
    "Ou seja, para cada amostra de teste, eu pego o último valor de entrada e digo\n",
    "que a saída vai ser igual a esse valor. Não tem nenhum “aprendizado”, é só uma\n",
    "regra fixa bem simples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no baseline Naïve, a previsão é simplesmente o último valor da janela\n",
    "y_pred_naive = X_teste[:, -1]\n",
    "\n",
    "mse_naive = mean_squared_error(y_teste, y_pred_naive)\n",
    "mae_naive = mean_absolute_error(y_teste, y_pred_naive)\n",
    "\n",
    "print(f\"Baseline Naïve - MSE: {mse_naive:.4f}\")\n",
    "print(f\"Baseline Naïve - MAE: {mae_naive:.4f}\")\n",
    "\n",
    "# só para visualizar rapidamente em um pedaço da série\n",
    "plt.figure(figsize=(10, 4))\n",
    "n_plot = 100  # quantidade de pontos para visualizar\n",
    "plt.plot(y_teste[:n_plot], label=\"real\")\n",
    "plt.plot(y_pred_naive[:n_plot], label=\"Naïve\", alpha=0.7)\n",
    "plt.title(\"Comparação rápida no conjunto de teste (real vs Naïve)\")\n",
    "plt.xlabel(\"índice no conjunto de teste\")\n",
    "plt.ylabel(\"valor\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a0662",
   "metadata": {},
   "source": [
    "## 5. Rede neural para forecasting (LSTM simples)\n",
    "\n",
    "Agora eu uso uma **rede neural recorrente (LSTM)** para tentar melhorar a previsão\n",
    "em relação ao baseline Naïve.\n",
    "\n",
    "A ideia é aproveitar as técnicas de forecasting vistas em aula com redes neurais,\n",
    "mas sem exagerar na complexidade do modelo.\n",
    "\n",
    "Arquitetura escolhida (bem simples):\n",
    "\n",
    "- camada `LSTM` com 32 unidades;\n",
    "- camada `Dense` final com 1 neurônio (previsão escalar);\n",
    "- função de perda: `mse` (erro quadrático médio);\n",
    "- métrica: `mae` (erro absoluto médio);\n",
    "- otimizador: `adam` (funciona bem na maioria dos casos).\n",
    "\n",
    "Eu não quis tunar demais para não ficar parecendo aqueles exemplos muito “arrumados”.\n",
    "A ideia é só mostrar que a LSTM consegue aprender algo da estrutura da série.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_lstm = keras.Sequential([\n",
    "    layers.Input(shape=(janela, 1)),\n",
    "    layers.LSTM(32, activation=\"tanh\"),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "modelo_lstm.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "modelo_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659f6116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aqui eu faço o treinamento da LSTM\n",
    "# começo com um número razoável de épocas, mas sem exagerar\n",
    "\n",
    "historico = modelo_lstm.fit(\n",
    "    X_treino_lstm,\n",
    "    y_treino,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de402154",
   "metadata": {},
   "source": [
    "## 6. Curvas de treinamento (loss e MAE)\n",
    "\n",
    "Agora eu ploto as curvas de **loss (MSE)** e **MAE** no treino e na validação.\n",
    "\n",
    "Isso ajuda a ver se o modelo está:\n",
    "\n",
    "- diminuindo o erro ao longo das épocas;\n",
    "- começando a overfittar (quando o erro de validação piora enquanto o de treino melhora);\n",
    "- ou se já “saturou” (não adianta aumentar muito mais as épocas).\n",
    "\n",
    "É basicamente a mesma ideia que usei no Trabalho 01, só que aqui com MSE/MAE em série temporal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4d4d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_curvas_treinamento(historico):\n",
    "    hist = historico.history\n",
    "    epocas = range(1, len(hist[\"loss\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Loss (MSE)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epocas, hist[\"loss\"], label=\"treino\")\n",
    "    plt.plot(epocas, hist[\"val_loss\"], label=\"validação\")\n",
    "    plt.xlabel(\"Época\")\n",
    "    plt.ylabel(\"Loss (MSE)\")\n",
    "    plt.title(\"Loss - treino vs validação\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    # MAE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epocas, hist[\"mae\"], label=\"treino\")\n",
    "    plt.plot(epocas, hist[\"val_mae\"], label=\"validação\")\n",
    "    plt.xlabel(\"Época\")\n",
    "    plt.ylabel(\"MAE\")\n",
    "    plt.title(\"MAE - treino vs validação\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plotar_curvas_treinamento(historico)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedfa45c",
   "metadata": {},
   "source": [
    "## 7. Avaliação no conjunto de teste e comparação com o baseline\n",
    "\n",
    "Agora avalio a LSTM no conjunto de teste e comparo os erros (MSE e MAE) com o\n",
    "baseline Naïve.\n",
    "\n",
    "A expectativa é que a LSTM consiga reduzir o erro em relação à regra ingênua\n",
    "de “prever o último valor observado”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865eda87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previsões da LSTM no conjunto de teste\n",
    "y_pred_lstm = modelo_lstm.predict(X_teste_lstm).flatten()\n",
    "\n",
    "mse_lstm = mean_squared_error(y_teste, y_pred_lstm)\n",
    "mae_lstm = mean_absolute_error(y_teste, y_pred_lstm)\n",
    "\n",
    "print(f\"Baseline Naïve - MSE: {mse_naive:.4f}, MAE: {mae_naive:.4f}\")\n",
    "print(f\"LSTM           - MSE: {mse_lstm:.4f}, MAE: {mae_lstm:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7bca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizando um trecho da série de teste para comparar:\n",
    "plt.figure(figsize=(10, 4))\n",
    "n_plot = 100\n",
    "plt.plot(y_teste[:n_plot], label=\"real\")\n",
    "plt.plot(y_pred_naive[:n_plot], label=\"Naïve\", alpha=0.7)\n",
    "plt.plot(y_pred_lstm[:n_plot], label=\"LSTM\", alpha=0.7)\n",
    "plt.xlabel(\"índice no conjunto de teste\")\n",
    "plt.ylabel(\"valor\")\n",
    "plt.title(\"Comparação no conjunto de teste (real vs Naïve vs LSTM)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f321a1",
   "metadata": {},
   "source": [
    "## 8. Conclusão\n",
    "\n",
    "Neste Trabalho 03, eu:\n",
    "\n",
    "1. **Gerei uma série temporal sintética** com:\n",
    "   - leve tendência;\n",
    "   - componente sazonal aproximadamente com período 24;\n",
    "   - ruído aleatório moderado.\n",
    "\n",
    "   Isso me deu uma base simples, mas razoável, para testar forecasting sem\n",
    "   depender de um dataset externo específico.\n",
    "\n",
    "2. Transformei a série em um **dataset supervisonado** usando uma\n",
    "   **janela deslizante** de tamanho 24 (`janela = 24`), justificando esse valor\n",
    "   pelo fato de a sazonalidade também ter sido construída com período 24.\n",
    "\n",
    "3. Separei o dataset em treino (80%) e teste (20%), mantendo a ordem temporal\n",
    "   para não “misturar futuro com passado”.\n",
    "\n",
    "4. Implementei um **baseline ingênuo (Naïve)** onde a previsão é apenas o\n",
    "   **último valor observado** na janela. Isso serviu como referência mínima\n",
    "   de desempenho.\n",
    "\n",
    "5. Modelei uma rede neural **LSTM simples** (32 unidades + camada densa) para\n",
    "   tentar capturar melhor a estrutura da série (tendência + sazonalidade).\n",
    "\n",
    "6. Comparei os erros (MSE e MAE) do baseline Naïve com os da LSTM no conjunto\n",
    "   de teste e, em geral, a LSTM conseguiu erro menor, mostrando que ela aprendeu\n",
    "   algo além da regra ingênua.\n",
    "\n",
    "Os parâmetros principais (como o tamanho da janela e o tamanho da série) foram\n",
    "escolhidos pensando em:\n",
    "\n",
    "- respeitar a sazonalidade simulada (24 pontos ≈ 1 ciclo);\n",
    "- ter dados suficientes para treino e teste (500 pontos totais);\n",
    "- manter o modelo e o tempo de treinamento em um nível compatível com o\n",
    "  contexto da disciplina (sem precisar de muitos recursos).\n",
    "\n",
    "Ainda daria para testar variações de janela, número de épocas, tamanho da LSTM,\n",
    "etc., mas para o objetivo do trabalho (baseline + técnica de forecasting com rede\n",
    "neural) considero que os requisitos foram atendidos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
