{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a19dba",
   "metadata": {},
   "source": [
    "# Trabalho 01 – Implementação do Backpropagation em Python (MLP)\n",
    "\n",
    "Este notebook é para o trabalho de **Implementação do Backpropagation em Python** da disciplina de **Redes Neurais Artificiais (RNA)**.\n",
    "\n",
    "### Enunciado (resumido)\n",
    "\n",
    "- Implementar e testar um **Multi Layer Perceptron (MLP)** \"na mão\" (usando Python / NumPy).\n",
    "- Comparar o resultado com o **MLP implementado no Scikit-Learn**.\n",
    "- O MLP implementado deve aceitar parâmetros para:\n",
    "  - quantidade de camadas;\n",
    "  - quantidade de neurônios em cada camada;\n",
    "  - função de ativação utilizada em cada camada.\n",
    "\n",
    "A ideia aqui é mais didática: eu ainda não tenho muita prática com redes neurais,\n",
    "então provavelmente dá pra melhorar o código, mas o objetivo principal é ver o \n",
    "**backpropagation funcionando** e conseguir comparar com a biblioteca.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99011be7",
   "metadata": {},
   "source": [
    "## 1. Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # para investigar a curva de erro\n",
    "\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Aqui eu escolhi o make_moons porque é um problema simples 2D, mas não linear.\n",
    "# Fica mais fácil de testar se o MLP aprendeu alguma coisa \"de verdade\".\n",
    "dados_X, rotulos_y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "\n",
    "# Separando em treino e teste (80% / 20%)\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(\n",
    "    dados_X, rotulos_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Normalização: nas aulas e na documentação falam que ajuda bastante em MLP,\n",
    "# então resolvi padronizar as features.\n",
    "normalizador = StandardScaler()\n",
    "X_treino = normalizador.fit_transform(X_treino)\n",
    "X_teste = normalizador.transform(X_teste)\n",
    "\n",
    "qtd_caracteristicas = X_treino.shape[1]\n",
    "qtd_classes = len(np.unique(y_treino))\n",
    "\n",
    "print(\"qtd_caracteristicas:\", qtd_caracteristicas)\n",
    "print(\"qtd_classes:\", qtd_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537bca30",
   "metadata": {},
   "source": [
    "## 2. Implementação do MLP \"do zero\" (NumPy)\n",
    "\n",
    "Aqui eu implementei uma classe `MLP` bem simples, com:\n",
    "\n",
    "- `tamanhos_camadas`: lista com o tamanho de cada camada (entrada, ocultas e saída)\n",
    "- `ativacoes`: lista com a função de ativação de cada camada (oculta/saída)\n",
    "- parâmetros de treinamento:\n",
    "  - `taxa_aprendizado`\n",
    "  - `epocas`\n",
    "  - `semente` (para reprodução dos resultados)\n",
    "\n",
    "A parte em que eu mais tive dúvida foi o **backpropagation**, principalmente:\n",
    "- conferir se as dimensões das matrizes estavam certas (W, delta, etc.)\n",
    "- ter certeza de que eu estava usando a derivada da ativação correta em cada camada.\n",
    "\n",
    "Também acrescentei um `historico_erro` para conseguir plotar a curva de treinamento\n",
    "e ver melhor quando a rede começa de fato a aprender.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc8224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(\n",
    "        self,\n",
    "        tamanhos_camadas,\n",
    "        ativacoes,\n",
    "        taxa_aprendizado=0.1,\n",
    "        epocas=1000,\n",
    "        semente=None,\n",
    "        mostrar_erro=True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        tamanhos_camadas: lista com o tamanho de cada camada, incluindo entrada e saída.\n",
    "            Ex: [2, 10, 5, 2]  -> entrada com 2, duas camadas ocultas (10 e 5) e saída com 2 neurônios.\n",
    "        ativacoes: lista com o nome da ativação pra cada camada oculta/saída.\n",
    "            Ex: [\"tanh\", \"tanh\", \"softmax\"]  (mesmo tamanho de tamanhos_camadas - 1)\n",
    "        \"\"\"\n",
    "        if len(ativacoes) != len(tamanhos_camadas) - 1:\n",
    "            raise ValueError(\"A lista de ativacoes deve ter len(tamanhos_camadas) - 1\")\n",
    "\n",
    "\n",
    "        self.tamanhos_camadas = tamanhos_camadas\n",
    "        self.ativacoes = ativacoes\n",
    "        self.taxa_aprendizado = taxa_aprendizado\n",
    "        self.epocas = epocas\n",
    "        self.semente = semente\n",
    "        self.mostrar_erro = mostrar_erro\n",
    "\n",
    "        # número de camadas que têm pesos (não conta a entrada)\n",
    "        self.num_camadas = len(tamanhos_camadas) - 1\n",
    "\n",
    "        # vou guardar o histórico de erro pra conseguir investigar depois\n",
    "        self.historico_erro = []\n",
    "\n",
    "        # só por precaução, inicializo rotulos_ como None\n",
    "        self.rotulos_ = None\n",
    "\n",
    "        self._inicializar_pesos()\n",
    "\n",
    "    def _inicializar_pesos(self):\n",
    "        # aqui eu mudei a inicialização porque com pesos muito pequenos\n",
    "        # a rede parecia ficar \"travada\" em algo quase linear\n",
    "        gerador = np.random.RandomState(self.semente)\n",
    "        self.pesos = []\n",
    "        self.biases = []\n",
    "\n",
    "        for i in range(self.num_camadas):\n",
    "            entradas = self.tamanhos_camadas[i]\n",
    "            saidas = self.tamanhos_camadas[i + 1]\n",
    "\n",
    "            # tentativa de inicialização um pouco mais \"esperta\" (tipo Xavier simples)\n",
    "            # (pra ser sincero eu não lembro o nome certinho da técnica, vi algo parecido em material de rede)\n",
    "            limite = np.sqrt(1.0 / entradas)\n",
    "            w = gerador.uniform(-limite, limite, size=(entradas, saidas))\n",
    "            b = np.zeros(saidas)\n",
    "\n",
    "            self.pesos.append(w)\n",
    "            self.biases.append(b)\n",
    "\n",
    "    def _funcao_ativacao(self, z, nome):\n",
    "        # aqui resolvi usar nomes em inglês mesmo, tipo 'tanh', 'relu', 'sigmoid', 'softmax'\n",
    "        if nome == \"sigmoid\":\n",
    "            return 1.0 / (1.0 + np.exp(-z))\n",
    "        elif nome == \"tanh\":\n",
    "            return np.tanh(z)\n",
    "        elif nome == \"relu\":\n",
    "            return np.maximum(0, z)\n",
    "        elif nome == \"linear\":\n",
    "            return z\n",
    "        elif nome == \"softmax\":\n",
    "            # normalmente uso softmax só na última camada (saída)\n",
    "            exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "            return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Função de ativação desconhecida: {nome}\")\n",
    "\n",
    "    def _derivada_ativacao(self, z, nome):\n",
    "        # derivadas básicas das ativações\n",
    "        if nome == \"sigmoid\":\n",
    "            sig = 1.0 / (1.0 + np.exp(-z))\n",
    "            return sig * (1.0 - sig)\n",
    "        elif nome == \"tanh\":\n",
    "            t = np.tanh(z)\n",
    "            return 1.0 - t**2\n",
    "        elif nome == \"relu\":\n",
    "            return (z > 0).astype(float)\n",
    "        elif nome == \"linear\":\n",
    "            return np.ones_like(z)\n",
    "        elif nome == \"softmax\":\n",
    "            # pra softmax + cross-entropy eu não uso essa derivada aqui\n",
    "            return np.ones_like(z)\n",
    "        else:\n",
    "            raise ValueError(f\"Função de ativação desconhecida: {nome}\")\n",
    "\n",
    "    def _forward(self, X):\n",
    "        \"\"\"\n",
    "        Passada pra frente (forward):\n",
    "        - calcula z^l = a^{l-1} W^l + b^l\n",
    "        - aplica a função de ativação pra obter a^l\n",
    "\n",
    "        Aqui preciso guardar:\n",
    "        - todas as ativações (a^l)\n",
    "        - todos os z^l\n",
    "\n",
    "        porque o backpropagation depois usa isso.\n",
    "        \"\"\"\n",
    "        ativacao = X\n",
    "        ativacoes = [ativacao]  # a^0 = X (entrada)\n",
    "        zs = []                 # lista com todos os z^l\n",
    "\n",
    "        for i in range(self.num_camadas):\n",
    "            w = self.pesos[i]\n",
    "            b = self.biases[i]\n",
    "\n",
    "            z = ativacao @ w + b  # produto matricial + bias\n",
    "            zs.append(z)\n",
    "\n",
    "            nome_ativ = self.ativacoes[i]\n",
    "            ativacao = self._funcao_ativacao(z, nome_ativ)\n",
    "            ativacoes.append(ativacao)\n",
    "\n",
    "        return zs, ativacoes\n",
    "\n",
    "    def _calcular_erro(self, y_one_hot, y_pred):\n",
    "        \"\"\"\n",
    "        Se a última camada for softmax, uso cross-entropy.\n",
    "        Se não, faço um MSE simples (deixei aqui mais pra generalizar).\n",
    "        \"\"\"\n",
    "        ultima_ativ = self.ativacoes[-1]\n",
    "        if ultima_ativ == \"softmax\":\n",
    "            eps = 1e-8\n",
    "            return -np.mean(np.sum(y_one_hot * np.log(y_pred + eps), axis=1))\n",
    "        else:\n",
    "            return 0.5 * np.mean(np.sum((y_pred - y_one_hot) ** 2, axis=1))\n",
    "\n",
    "    def _backpropagation(self, zs, ativacoes, y_one_hot):\n",
    "        \"\"\"\n",
    "        Implementação do backpropagation.\n",
    "\n",
    "        Aqui foi a parte que eu mais tive dificuldade.\n",
    "        A ideia geral:\n",
    "        - calcular o erro na saída (delta da última camada)\n",
    "        - ir \"voltando\" camada por camada, aplicando a regra da cadeia\n",
    "\n",
    "        zs: lista com os z^l\n",
    "        ativacoes: lista com os a^l\n",
    "        y_one_hot: rótulos em formato one-hot\n",
    "        \"\"\"\n",
    "        m = y_one_hot.shape[0]  # quantidade de exemplos\n",
    "\n",
    "        grad_pesos = [None] * self.num_camadas\n",
    "        grad_biases = [None] * self.num_camadas\n",
    "\n",
    "        y_pred = ativacoes[-1]\n",
    "        ultima_ativ = self.ativacoes[-1]\n",
    "\n",
    "        # erro na camada de saída\n",
    "        if ultima_ativ == \"softmax\":\n",
    "            # derivada de cross-entropy + softmax fica bem simples: y_pred - y_true\n",
    "            delta = y_pred - y_one_hot\n",
    "        else:\n",
    "            # se fosse MSE, seria algo assim:\n",
    "            delta = (y_pred - y_one_hot) * self._derivada_ativacao(zs[-1], ultima_ativ)\n",
    "\n",
    "        # loop de trás pra frente (camadas L, L-1, ..., 1)\n",
    "        for camada in reversed(range(self.num_camadas)):\n",
    "            a_anterior = ativacoes[camada]  # a^{l}\n",
    "\n",
    "            # gradiente em relação aos pesos e biases\n",
    "            grad_pesos[camada] = a_anterior.T @ delta / m\n",
    "            grad_biases[camada] = np.mean(delta, axis=0)\n",
    "\n",
    "            if camada != 0:\n",
    "                nome_ativ_anterior = self.ativacoes[camada - 1]\n",
    "                # propagando o erro pra camada anterior\n",
    "                delta = (delta @ self.pesos[camada].T) * self._derivada_ativacao(\n",
    "                    zs[camada - 1], nome_ativ_anterior\n",
    "                )\n",
    "\n",
    "        return grad_pesos, grad_biases\n",
    "\n",
    "    def treinar(self, X, y):\n",
    "        \"\"\"\n",
    "        Treinamento usando gradiente descendente simples.\n",
    "\n",
    "        y pode vir como vetor de inteiros (0,1,2,...) que eu converto pra one-hot.\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "\n",
    "        # reseta o histórico de erro sempre que treinar de novo\n",
    "        self.historico_erro = []\n",
    "\n",
    "        # converte para one-hot se for apenas um vetor de inteiros\n",
    "        if y.ndim == 1:\n",
    "            self.rotulos_, indices = np.unique(y, return_inverse=True)\n",
    "            qtd_classes = len(self.rotulos_)\n",
    "            y_one_hot = np.eye(qtd_classes)[indices]\n",
    "        else:\n",
    "            # se já vier em one-hot, assumo que está ok\n",
    "            y_one_hot = y\n",
    "            self.rotulos_ = np.arange(y.shape[1])\n",
    "\n",
    "        for epoca in range(self.epocas):\n",
    "            zs, ativacoes = self._forward(X)\n",
    "            y_pred = ativacoes[-1]\n",
    "\n",
    "            erro = self._calcular_erro(y_one_hot, y_pred)\n",
    "            grad_pesos, grad_biases = self._backpropagation(zs, ativacoes, y_one_hot)\n",
    "\n",
    "            # guarda o erro pra investigar depois\n",
    "            self.historico_erro.append(erro)\n",
    "\n",
    "            # atualização dos pesos (gradiente descendente)\n",
    "            for i in range(self.num_camadas):\n",
    "                self.pesos[i] -= self.taxa_aprendizado * grad_pesos[i]\n",
    "                self.biases[i] -= self.taxa_aprendizado * grad_biases[i]\n",
    "\n",
    "            if self.mostrar_erro and (epoca % 100 == 0 or epoca == self.epocas - 1):\n",
    "                print(f\"Época {epoca}, erro = {erro:.4f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def prever_proba(self, X):\n",
    "        X = np.asarray(X)\n",
    "        _, ativacoes = self._forward(X)\n",
    "        return ativacoes[-1]\n",
    "\n",
    "    def prever(self, X):\n",
    "        probas = self.prever_proba(X)\n",
    "        indices = np.argmax(probas, axis=1)\n",
    "        # se por algum motivo rotulos_ não existir (por ex, se eu esquecer de chamar treinar),\n",
    "        # eu devolvo os índices brutos mesmo (0, 1, 2, ...)\n",
    "        if self.rotulos_ is None:\n",
    "            return indices\n",
    "        return self.rotulos_[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca04ae9d",
   "metadata": {},
   "source": [
    "## 3. Treinamento do MLP implementado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce1829b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitetura do MLP manual:\n",
    "# entrada -> 20 neurônios -> 20 neurônios -> saída (qtd_classes)\n",
    "tamanhos_camadas = [qtd_caracteristicas, 20, 20, qtd_classes]\n",
    "\n",
    "# Ativações correspondentes às camadas (sem contar a entrada)\n",
    "ativacoes = [\"tanh\", \"tanh\", \"softmax\"]\n",
    "\n",
    "mlp_manual = MLP(\n",
    "    tamanhos_camadas=tamanhos_camadas,\n",
    "    ativacoes=ativacoes,\n",
    "    taxa_aprendizado=0.05,  # taxa de aprendizado um pouco menor\n",
    "    epocas=3000,            # mais épocas pra ver se a loss desce bem\n",
    "    semente=42,\n",
    "    mostrar_erro=True,\n",
    ")\n",
    "\n",
    "mlp_manual.treinar(X_treino, y_treino)\n",
    "\n",
    "y_pred_mlp_manual = mlp_manual.prever(X_teste)\n",
    "acuracia_manual = accuracy_score(y_teste, y_pred_mlp_manual)\n",
    "\n",
    "print(\"Acurácia MLP implementado na mão:\", acuracia_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6621a94",
   "metadata": {},
   "source": [
    "## 4. Investigando a curva de erro (loss)\n",
    "\n",
    "Aqui eu quis ver melhor como o erro se comporta ao longo das épocas.\n",
    "Usei o `historico_erro` que foi guardado durante o treinamento e plotei\n",
    "a curva abaixo.\n",
    "\n",
    "Isso ajuda a enxergar melhor em que momento o modelo começa a sair do\n",
    "“chute aleatório” (erro ≈ 0,693 em classificação binária com softmax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(mlp_manual.historico_erro)\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Erro (loss)\")\n",
    "plt.title(\"Curva de treinamento do MLP (implementado na mão)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3bba4b",
   "metadata": {},
   "source": [
    "## 5. Visualizando a fronteira de decisão do MLP implementado\n",
    "\n",
    "Além da curva de erro, eu quis ver também a **fronteira de decisão** aprendida\n",
    "pelo MLP que eu implementei. \n",
    "\n",
    "Esse tipo de gráfico ajuda a enxergar se o modelo realmente separou bem as duas\n",
    "classes no plano 2D (no caso do `make_moons`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e6d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_fronteira_decisao_mlp_manual(modelo, X, y, titulo=\"Fronteira de decisão - MLP manual\"):\n",
    "    \"\"\"\n",
    "    Desenha a fronteira de decisão em 2D para o MLP implementado na mão.\n",
    "\n",
    "    Obs: aqui eu uso X já normalizado (X_treino), porque foi assim que eu treinei o modelo.\n",
    "    \"\"\"\n",
    "    passo = 0.02  # quanto menor o passo, mais detalhado (e mais pesado)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, passo),\n",
    "        np.arange(y_min, y_max, passo)\n",
    "    )\n",
    "\n",
    "    X_grade = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    Z = modelo.prever(X_grade)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\", alpha=0.7)\n",
    "    plt.title(titulo)\n",
    "    plt.xlabel(\"feature 1 (normalizada)\")\n",
    "    plt.ylabel(\"feature 2 (normalizada)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# aqui eu chamo a função para o meu MLP manual, usando os dados de treino\n",
    "plotar_fronteira_decisao_mlp_manual(mlp_manual, X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5390a25c",
   "metadata": {},
   "source": [
    "## 6. Comparação com o MLPClassifier do Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb41cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora eu uso o MLPClassifier do Scikit-Learn com uma arquitetura parecida:\n",
    "mlp_sklearn = MLPClassifier(\n",
    "    hidden_layer_sizes=(20, 20),\n",
    "    activation=\"tanh\",\n",
    "    solver=\"sgd\",          # pra ficar mais parecido com gradiente descendente simples\n",
    "    learning_rate_init=0.05,\n",
    "    max_iter=3000,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "mlp_sklearn.fit(X_treino, y_treino)\n",
    "\n",
    "y_pred_sklearn = mlp_sklearn.predict(X_teste)\n",
    "acuracia_sklearn = accuracy_score(y_teste, y_pred_sklearn)\n",
    "\n",
    "print(\"Acurácia MLPClassifier (Scikit-Learn):\", acuracia_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a8d63b",
   "metadata": {},
   "source": [
    "## 7. Visualizando a fronteira de decisão do MLPClassifier (Scikit-Learn)\n",
    "\n",
    "Para comparar melhor, também plotei a fronteira de decisão do `MLPClassifier`\n",
    "do Scikit-Learn, usando a mesma ideia de grade de pontos 2D.\n",
    "\n",
    "Daria para generalizar e fazer uma função única, mas eu preferi separar em duas\n",
    "funções para não complicar muito a lógica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fb3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_fronteira_decisao_sklearn(modelo, X, y, titulo=\"Fronteira de decisão - MLP (Scikit-Learn)\"):\n",
    "    \"\"\"\n",
    "    Desenha a fronteira de decisão em 2D para o MLPClassifier do Scikit-Learn.\n",
    "\n",
    "    Aqui também uso X normalizado (X_treino), igual no treinamento.\n",
    "    \"\"\"\n",
    "    passo = 0.02\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, passo),\n",
    "        np.arange(y_min, y_max, passo)\n",
    "    )\n",
    "\n",
    "    X_grade = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    Z = modelo.predict(X_grade)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors=\"k\", alpha=0.7)\n",
    "    plt.title(titulo)\n",
    "    plt.xlabel(\"feature 1 (normalizada)\")\n",
    "    plt.ylabel(\"feature 2 (normalizada)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# chamada para o MLP do Scikit-Learn\n",
    "plotar_fronteira_decisao_sklearn(mlp_sklearn, X_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe23759",
   "metadata": {},
   "source": [
    "## 8. Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa25cb64",
   "metadata": {},
   "source": [
    "Neste trabalho eu:\n",
    "\n",
    "1. Implementei um **MLP do zero** em Python, usando apenas NumPy:\n",
    "   - a classe `MLP` recebe como parâmetros:\n",
    "     - `tamanhos_camadas` (quantidade de camadas e neurônios em cada uma);\n",
    "     - `ativacoes` (função de ativação para cada camada oculta e saída);\n",
    "     - hiperparâmetros de treinamento (taxa de aprendizado, épocas, etc.).\n",
    "   - implementei o **forward** e o **backpropagation** manualmente.\n",
    "   - armazenei o `historico_erro` para investigar a curva de treinamento.\n",
    "\n",
    "2. Treinei esse MLP em um conjunto de dados de exemplo (`make_moons`), fazendo:\n",
    "   - separação em treino e teste;\n",
    "   - normalização das entradas;\n",
    "   - cálculo da acurácia no conjunto de teste;\n",
    "   - análise visual da curva de erro ao longo das épocas;\n",
    "   - visualização da fronteira de decisão aprendida pelo modelo.\n",
    "\n",
    "3. Treinei também um **MLPClassifier do Scikit-Learn** com uma arquitetura parecida e:\n",
    "   - comparei a acurácia do meu MLP com a acurácia do MLP do Scikit-Learn;\n",
    "   - plotei a fronteira de decisão de ambos os modelos.\n",
    "\n",
    "Os resultados não ficaram exatamente iguais, mas as acurácias ficaram na mesma ordem\n",
    "de grandeza, o que indica que a implementação do backpropagation está funcionando\n",
    "de forma razoável.\n",
    "\n",
    "Ainda tenho dúvidas em alguns detalhes, principalmente na parte de:\n",
    "- escolha dos hiperparâmetros (taxa de aprendizado, número de épocas);\n",
    "- inicialização de pesos mais \"esperta\" (essa que usei foi inspirada em exemplos, mas ainda estou entendendo melhor).\n",
    "\n",
    "Mesmo assim, consegui cumprir os requisitos principais da tarefa:\n",
    "- implementar o MLP com parâmetros configuráveis de camadas/neurônios/ativações;\n",
    "- comparar o desempenho com o MLP do Scikit-Learn;\n",
    "- e observar, tanto numericamente quanto visualmente, o comportamento do treinamento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417a5062",
   "metadata": {},
   "source": [
    "## Referência aos notebooks originais do professor\n",
    "\n",
    "Durante o desenvolvimento deste trabalho, eu tentei utilizar como base o seguinte notebook,\n",
    "que em princípio seria a referência principal para backpropagation com uma camada oculta:\n",
    "\n",
    "- `aula4a_Single_Hidden_Layer_Backpropagation.ipynb`  \n",
    "  Link informado: https://github.com/fboldt/aulasann/blob/main/aula4a_Single_Hidden_Layer_Backpropagation.ipynb  \n",
    "\n",
    "No momento da realização do trabalho, esse arquivo **não estava disponível** (não consegui\n",
    "acessar o conteúdo do notebook).\n",
    "\n",
    "Como material de apoio conceitual, acabei utilizando principalmente:\n",
    "\n",
    "- `aula05b_single_hidden_layer.ipynb`  \n",
    "  Disponível em: https://github.com/fboldt/aulasann/blob/main/aula05b_single_hidden_layer.ipynb  \n",
    "\n",
    "Esse notebook foi usado para revisar a ideia geral do algoritmo de backpropagation em uma\n",
    "rede com uma camada escondida, e a partir dele escrevi minha própria classe `MLP` mais genérica.\n",
    "\n",
    "A comparação com o `MLPClassifier` do Scikit-Learn foi feita com um exemplo implementado por mim,\n",
    "seguindo o que vimos em aula sobre usar o MLP do Scikit-Learn como \"padrão de comparação\".\n",
    "\n",
    "Para contextualizar a organização do repositório do professor, outros arquivos como\n",
    "`aula05c_multilayer.ipynb` e `aula06a_mlp_scikit_learn.ipynb` parecem dar sequência ao mesmo\n",
    "tema (multicamadas e uso direto do MLP do Scikit-Learn), mas a implementação final apresentada\n",
    "aqui foi escrita por mim a partir dos conceitos vistos em aula.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
